{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introducción a PyTorch - Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Documentación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "Canceled. \n",
      "View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "torch.  # <Tab> para obtener lista de opciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Module()"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.Module() # <Shift>+<Tab> para una breve descripción del módulo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ver toda las opciones con `*Tensor`?\n",
    "# <esc> para salir\n",
    "torch.*Tensor?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.nn.Module?\n",
    "torch.nn.Module??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De la documentación de pytorch:\n",
    "\n",
    "``Tensors are similar to NumPy’s ndarrays, except that tensors can run on GPUs or other hardware accelerators. In fact, tensors and NumPy arrays can often share the same underlying memory, eliminating the need to copy data (see Bridge with NumPy). Tensors are also optimized for automatic differentiation (we’ll see more about that later in the Autograd section)``"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inicialización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Desde datos. Pueden indicar el tipo\n",
    "data = [[1, 2],[3, 4]]\n",
    "x_data = torch.tensor(data)\n",
    "# x_data = torch.tensor([[1, 2],[3, 4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Desde un array de numpy\n",
    "np_array = np.array(data)\n",
    "x_np = torch.from_numpy(np_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ones Tensor: \n",
      " tensor([[1, 1],\n",
      "        [1, 1]]) \n",
      "\n",
      "Random Tensor: \n",
      " tensor([[0.4159, 0.5577],\n",
      "        [0.8716, 0.0494]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Desde otro tensor\n",
    "x_ones = torch.ones_like(x_data) # retains the properties of x_data\n",
    "print(f\"Ones Tensor: \\n {x_ones} \\n\")\n",
    "\n",
    "x_rand = torch.rand_like(x_data, dtype=torch.float) # overrides the datatype of x_data\n",
    "print(f\"Random Tensor: \\n {x_rand} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Constructors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3., 4., 5., 6., 7., 8.])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create tensor from 3 to 8, with each having a space of 1\n",
    "torch.arange(3., 8 + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 5.7000,  2.7000, -0.3000])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create tensor from 5.7 to -2.1 with each having a space of -3\n",
    "torch.arange(5.7, -2.1, -3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3.0000, 3.2632, 3.5263, 3.7895, 4.0526, 4.3158, 4.5789, 4.8421, 5.1053,\n",
       "         5.3684, 5.6316, 5.8947, 6.1579, 6.4211, 6.6842, 6.9474, 7.2105, 7.4737,\n",
       "         7.7368, 8.0000]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# returns a 1D tensor of steps equally spaced points between start=3, end=8 and steps=20\n",
    "torch.linspace(3, 8, 20).view(1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor filled with 0's\n",
    "torch.zeros(3, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.]]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor filled with 1's\n",
    "torch.ones(3, 2, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 0., 1.]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor with the diagonal filled with 1\n",
    "torch.eye(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Numpy bridge\n",
    "plt.hist(torch.randn(1000).numpy(), 100);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Atributos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of tensor: torch.Size([3, 4])\n",
      "Datatype of tensor: torch.float32\n",
      "Device tensor is stored on: cpu\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.rand(3,4)\n",
    "\n",
    "print(f\"Shape of tensor: {tensor.shape}\")\n",
    "print(f\"Datatype of tensor: {tensor.dtype}\")\n",
    "print(f\"Device tensor is stored on: {tensor.device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "point in a 12 dimensional space\n",
      "organised in 2 sub-dimensions\n"
     ]
    }
   ],
   "source": [
    "print(f'point in a {tensor.numel()} dimensional space')\n",
    "print(f'organised in {tensor.dim()} sub-dimensions')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First row:  tensor([1., 1., 1., 1.])\n",
      "First column:  tensor([1., 1., 1., 1.])\n",
      "Last column: tensor([1., 1., 1., 1.])\n",
      "tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.ones(4, 4)\n",
    "print('First row: ', tensor[0])\n",
    "print('First column: ', tensor[:, 0])\n",
    "print('Last column:', tensor[..., -1])\n",
    "tensor[:,1] = 0\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "t1 = torch.cat([tensor, tensor, tensor], dim=1)\n",
    "print(t1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vectores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3., 4.])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = torch.Tensor([1, 2, 3, 4])\n",
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dim: 1, size: 4\n"
     ]
    }
   ],
   "source": [
    "print(f'dim: {v.dim()}, size: {v.size()[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 0., 2., 0.])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = torch.Tensor([1, 0, 2, 0])\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 0., 6., 0.])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Element-wise multiplication\n",
    "# Equivalente a v.mul(w)\n",
    "v * w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7.)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scalar product: 1*1 + 2*0 + 3*2 + 4*0\n",
    "# Equivalente a v.matmul(w)\n",
    "v @ w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([8., 4., 1., 0., 3.])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In-place replacement of random number from 0 to 10\n",
    "# Complejo para autograd --> no recomendable\n",
    "x = torch.Tensor(5).random_(10)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1.,  4.,  9., 16.]) tensor([1., 2., 3., 4.])\n"
     ]
    }
   ],
   "source": [
    "# Square all elements in the tensor\n",
    "print(v.pow(2), v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2., 5., 3., 7.],\n",
       "        [4., 2., 1., 9.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a 2x4 tensor\n",
    "m = torch.Tensor([[2, 5, 3, 7],\n",
    "                  [4, 2, 1, 9]])\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.dim()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 -- 4 -- torch.Size([2, 4])\n"
     ]
    }
   ],
   "source": [
    "print(m.size(0), m.size(1), m.size(), sep=' -- ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2., 5., 3., 7.]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Indexes row 0, all columns (returns 1x4)\n",
    "m[[0], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2., 5., 3., 7.])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Indexes row 0, all columns (returns size 4)\n",
    "m[0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3., 4.])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = torch.arange(1., 4 + 1)\n",
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([49., 47.])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scalar product\n",
    "m @ v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2., 4.],\n",
       "        [5., 2.],\n",
       "        [3., 1.],\n",
       "        [7., 9.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.t_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2., 4.],\n",
       "        [5., 2.],\n",
       "        [3., 1.],\n",
       "        [7., 9.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 1., 1.],\n",
       "        [1., 0., 1., 1.],\n",
       "        [1., 0., 1., 1.],\n",
       "        [1., 0., 1., 1.]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3., 3., 3., 3.],\n",
       "        [3., 3., 3., 3.],\n",
       "        [3., 3., 3., 3.],\n",
       "        [3., 3., 3., 3.]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This computes the matrix multiplication between two tensors. y1, y2, y3 will have the same value\n",
    "y1 = tensor @ tensor.T\n",
    "y2 = tensor.matmul(tensor.T)\n",
    "\n",
    "y3 = torch.rand_like(tensor)\n",
    "torch.matmul(tensor, tensor.T, out=y3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 1., 1.],\n",
       "        [1., 0., 1., 1.],\n",
       "        [1., 0., 1., 1.],\n",
       "        [1., 0., 1., 1.]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This computes the element-wise product. z1, z2, z3 will have the same value\n",
    "z1 = tensor * tensor\n",
    "z2 = tensor.mul(tensor)\n",
    "\n",
    "z3 = torch.rand_like(tensor)\n",
    "torch.mul(tensor, tensor, out=z3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 1., 1.],\n",
       "        [1., 0., 1., 1.],\n",
       "        [1., 0., 1., 1.],\n",
       "        [1., 0., 1., 1.]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.0 <class 'float'>\n"
     ]
    }
   ],
   "source": [
    "# Elementos simples\n",
    "agg = tensor.sum()\n",
    "agg_item = agg.item()\n",
    "print(agg_item, type(agg_item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]]) \n",
      "\n",
      "tensor([[6., 5., 6., 6.],\n",
      "        [6., 5., 6., 6.],\n",
      "        [6., 5., 6., 6.],\n",
      "        [6., 5., 6., 6.]])\n"
     ]
    }
   ],
   "source": [
    "# In place\n",
    "print(tensor, \"\\n\")\n",
    "tensor.add_(5)\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conexión con Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: tensor([1., 1., 1., 1., 1.])\n",
      "n: [1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "# De tensor a numpy\n",
    "\n",
    "t = torch.ones(5)\n",
    "print(f\"t: {t}\")\n",
    "n = t.numpy()\n",
    "print(f\"n: {n}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: tensor([2., 2., 2., 2., 2.])\n",
      "n: [2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "t.add_(1)\n",
    "print(f\"t: {t}\")\n",
    "print(f\"n: {n}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# De numpy a tensor\n",
    "\n",
    "n = np.ones(5)\n",
    "t = torch.from_numpy(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n",
      "n: [2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "np.add(n, 1, out=n)\n",
    "print(f\"t: {t}\")\n",
    "print(f\"n: {n}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Casting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2., 5., 3., 7.],\n",
       "        [4., 2., 1., 9.]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2., 5., 3., 7.],\n",
       "        [4., 2., 1., 9.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is basically a 64 bit float tensor\n",
    "m_double = m.double()\n",
    "m_double"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 5, 3, 7],\n",
       "        [4, 2, 1, 9]], dtype=torch.uint8)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This creates a tensor of type int8\n",
    "m_byte = m.byte()\n",
    "m_byte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2., 5., 3., 7.],\n",
       "        [4., 2., 1., 9.]], device='cuda:0')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Move your tensor to GPU device 0 if there is one (first GPU in the system)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "m.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Almacenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "points = torch.ones(3, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternativa 1 : No es ideal porque no es compatible con otros módulos de python\n",
    "torch.save(points, 'points.t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternativa 2\n",
    "with open('points.t','wb') as f:\n",
    "   torch.save(points, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "points = torch.load('points.t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HDF \n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = h5py.File('points.hdf5', 'w')\n",
    "dset = f.create_dataset('coords', data=points.numpy())\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = h5py.File('points.hdf5', 'r')\n",
    "dset = f['coords']\n",
    "last_points = dset[-2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(last_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_points = torch.from_numpy(dset[-2:])\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b045fddb768a69d708aeb44bac4815a8765073d6505277d1278f194b80f63e22"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
